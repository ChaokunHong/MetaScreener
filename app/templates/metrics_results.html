{% extends "base.html" %}

{% block title %}Performance Metrics Analysis - AI Literature Screening Assistant{% endblock %}

{% block extra_head %}
<style>
    /* Balanced header styling */
    .page-header {
        background: linear-gradient(135deg, #f8fafc 0%, #f3f0ff 100%);
        padding: 1rem;
        border-radius: 6px;
        margin-bottom: 1.5rem;
        border: 1px solid #e5e7eb;
    }
    
    .page-header h1 {
        font-size: 1.25rem;
        color: #1e293b;
        margin: 0;
        font-weight: 600;
    }
    
    /* Clean metric cards */
    .metric-card-group {
        margin-bottom: 1.5rem;
        border-radius: 6px;
        overflow: hidden;
        border: 1px solid #e2e8f0;
        background: white;
    }
    
    .metric-card-group .card-header {
        background: linear-gradient(135deg, #f8fafc 0%, #e7e3ff 100%);
        color: #5b21b6;
        font-weight: 600;
        padding: 0.75rem 1rem;
        border: none;
    }
    
    .metric-card-group .card-header h3 {
        margin: 0;
        font-size: 1rem;
        display: flex;
        align-items: center;
    }
    
    .metric-card-group .card-body {
        padding: 1rem;
        background: white;
    }
    
    /* Simple metric value cards */
    .metric-value-card {
        background: #f8fafc;
        border: 1px solid #e2e8f0;
        border-radius: 4px;
        padding: 0.75rem;
        height: 100%;
        margin-bottom: 0.75rem;
        text-align: center;
    }
    
    .metric-value-card strong {
        display: block;
        font-size: 0.8rem;
        margin-bottom: 0.4rem;
        color: #6b46c1;
        font-weight: 600;
    }
    
    .metric-value {
        font-size: 1.4rem;
        font-weight: bold;
        display: block;
        margin-bottom: 0.4rem;
        color: #374151;
    }
    
    .explanation {
        font-size: 0.7rem;
        color: #64748b;
        line-height: 1.3;
    }
    
    /* Critical error card styling */
    .metric-value-card.critical-error {
        background: #fef2f2;
        border-color: #fecaca;
    }
    
    .metric-value-card.critical-error strong,
    .metric-value-card.critical-error .metric-value {
        color: #dc2626;
    }
    
    /* Simple confusion matrix styling */
    .matrix-table {
        background: white;
        border-radius: 4px;
        overflow: hidden;
        border: 1px solid #e2e8f0;
        margin-bottom: 0;
        font-size: 0.8rem;
    }
    
    .matrix-table th.actual-header,
    .matrix-table th.pred-header {
        background: #f1f5f9;
        color: #6b46c1;
        font-weight: 600;
        padding: 0.5rem;
        border: none;
        font-size: 0.75rem;
    }
    
    .matrix-table td {
        font-weight: 500;
        font-size: 0.85rem;
        text-align: center;
        vertical-align: middle;
        padding: 0.5rem;
        border: 1px solid #f1f5f9;
    }
    
    .cm-correct {
        background: #bbf7d0;
        color: #065f46;
        font-weight: 600;
        border: 2px solid var(--success-color);
    }
    
    .cm-incorrect {
        background: #fecaca;
        color: #991b1b;
        font-weight: 600;
        border: 2px solid #dc2626;
    }
    
    /* Balanced soft decision badges */
    .badge-include {
        background: #059669;
        color: white;
        padding: 0.2rem 0.5rem;
        border-radius: 3px;
        font-weight: 500;
        font-size: 0.7rem;
    }
    
    .badge-exclude {
        background: #dc2626;
        color: white;
        padding: 0.2rem 0.5rem;
        border-radius: 3px;
        font-weight: 500;
        font-size: 0.7rem;
    }
    
    .badge-maybe {
        background: #d97706;
        color: white;
        padding: 0.2rem 0.5rem;
        border-radius: 3px;
        font-weight: 500;
        font-size: 0.7rem;
    }
    
    .badge-secondary {
        background: #6b7280;
        color: white;
        padding: 0.2rem 0.4rem;
        border-radius: 10px;
        font-weight: 500;
        font-size: 0.65rem;
    }
    
    /* Simple comparison table styling */
    .comparison-table {
        background: white;
        border-radius: 4px;
        overflow: hidden;
        border: 1px solid #e2e8f0;
        font-size: 0.8rem;
    }
    
    .comparison-table thead th {
        background: linear-gradient(135deg, #f8fafc 0%, #e7e3ff 100%);
        color: #5b21b6;
        font-weight: 600;
        font-size: 0.75rem;
        padding: 0.5rem 0.4rem;
        border-bottom: 2px solid #e2e8f0;
        text-align: left;
        position: sticky;
        top: 0;
        z-index: 1;
    }
    
    .comparison-table tbody tr {
        border-bottom: 1px solid #f1f5f9;
    }
    
    .comparison-table tbody tr:hover {
        background-color: #faf9ff;
    }
    
    .comparison-table tbody tr:last-child {
        border-bottom: none;
    }
    
    .comparison-table td {
        padding: 0.4rem;
        border: none;
        font-size: 0.75rem;
        vertical-align: middle;
    }
    
    /* Match status styling */
    .match-true strong {
        color: #059669;
        font-weight: 600;
    }
    
    .match-false strong {
        color: #dc2626;
        font-weight: 600;
    }
    
    /* Simple summary paragraph styling */
    .summary-info {
        background: #f1f5f9;
        padding: 0.75rem;
        border-radius: 4px;
        border-left: 3px solid #6b46c1;
        margin-bottom: 1rem;
        font-size: 0.8rem;
        color: #374151;
    }
    
    /* Simple MAYBE analysis list styling */
    .maybe-list {
        background: #f8fafc;
        border-radius: 4px;
        padding: 0;
        margin-top: 0.75rem;
        overflow: hidden;
        border: 1px solid #e2e8f0;
    }
    
    .maybe-list .list-group-item {
        border: none;
        border-bottom: 1px solid #f1f5f9;
        background: transparent;
        font-size: 0.75rem;
        padding: 0.5rem 0.75rem;
    }
    
    .maybe-list .list-group-item:last-child {
        border-bottom: none;
    }
    
    /* Simple badge styling in lists */
    .badge-pill {
        padding: 0.2rem 0.5rem;
        border-radius: 10px;
        font-weight: 500;
        font-size: 0.65rem;
    }
    
    .badge-info {
        background: #3b82f6;
        color: white;
    }
    
    .badge-success {
        background: var(--success-color);
        color: white;
    }
    
    .badge-primary {
        background: #6b46c1;
        color: white;
    }
    
    /* Simple definitions section styling */
    .definitions-card {
        background: #f8fafc;
        border: 1px solid #e2e8f0;
    }
    
    .definitions-card .card-header {
        background: transparent;
        border-bottom: 1px solid #e2e8f0;
    }
    
    .definitions-card .btn-link {
        color: #6b46c1;
        text-decoration: none;
        font-weight: 500;
    }
    
    .definitions-card .btn-link:hover {
        color: #553c9a;
        text-decoration: none;
    }
    
    .definitions-card dl {
        margin-bottom: 0;
    }
    
    .definitions-card dt {
        color: #6b46c1;
        font-weight: 600;
        font-size: 0.75rem;
    }
    
    .definitions-card dd {
        color: #64748b;
        font-size: 0.75rem;
        line-height: 1.3;
    }
    
    /* Simple table responsive container */
    .table-responsive {
        max-height: 350px;
        overflow-y: auto;
        border-radius: 4px;
        border: 1px solid #e2e8f0;
    }
    
    /* Responsive adjustments */
    @media (max-width: 768px) {
        .page-header {
            padding: 0.75rem;
            text-align: center;
        }
        
        .metric-value-card {
            margin-bottom: 0.75rem;
        }
        
        .metric-value {
            font-size: 1.2rem;
        }
        
        .matrix-table,
        .comparison-table {
            font-size: 0.7rem;
        }
        
        .matrix-table th,
        .matrix-table td,
        .comparison-table th,
        .comparison-table td {
            padding: 0.3rem 0.2rem;
        }
    }
</style>
{% endblock %}

{% block content %}
    <div class="page-header">
        <div class="d-flex justify-content-between align-items-center">
            <h1><i class="fas fa-chart-line mr-2"></i>Performance Metrics & Analysis</h1>
            <div>
                {% if session_id %}
                <a href="{{ url_for('screen_full_dataset', session_id=session_id) }}" class="btn btn-success btn-sm mr-2" title="Screen the full dataset from the test file using current criteria and LLM settings.">
                    <i class="fas fa-play mr-1"></i>Screen Full Dataset (from Test)
                </a>
                {% endif %}
                <a href="{{ url_for('screening_actions_page') }}" class="btn btn-outline-secondary btn-sm">
                    <i class="fas fa-arrow-left mr-1"></i>Back to Screening Actions
                </a>
            </div>
        </div>
    </div>

    {% if metrics and matrix_3x3 and matrix_3x3.matrix_data and class_metrics %}
        <div class="summary-info">
            <strong><i class="fas fa-info-circle mr-2"></i>Analysis Summary:</strong>
            Analysis based on <strong>{{ total_samples }}</strong> samples where both AI and Human decisions (INCLUDE, MAYBE, EXCLUDE) were provided.
        </div>

        <!-- Overall Performance Section -->
        <div class="card metric-card-group">
            <div class="card-header">
                <h3><i class="fas fa-trophy mr-2"></i>Overall Performance</h3>
            </div>
            <div class="card-body">
                <div class="row">
                    <div class="col-md-3">
                        <div class="metric-value-card">
                            <strong>Overall Accuracy</strong>
                            <span class="metric-value">{{ "%.2f"|format(metrics.overall_accuracy * 100) }}%</span>
                            <p class="explanation">AI matched Human (I/M/E).</p>
                        </div>
                    </div>
                    <div class="col-md-3">
                        <div class="metric-value-card">
                             <strong>Cohen's Kappa</strong>
                             <span class="metric-value">{{ "%.2f"|format(metrics.cohens_kappa) }}</span>
                             <p class="explanation">AI-Human agreement (chance-corrected). >0.8 Exc, 0.6-0.8 Good.</p>
                        </div>
                    </div>
                    <div class="col-md-3">
                         <div class="metric-value-card">
                            <strong>Discrepancy Rate</strong>
                            <span class="metric-value">{{ "%.1f"|format(metrics.discrepancy_rate) }}%</span>
                            <p class="explanation">AI-Human disagreements.</p>
                        </div>
                    </div>
                    <div class="col-md-3">
                         <div class="metric-value-card critical-error">
                            <strong>Critical Error Rate (I→E)</strong>
                            <span class="metric-value">{{ "%.2f"|format(metrics.critical_error_rate_ie) }}%</span>
                            <p class="explanation">% where Human=INCLUDE but AI=EXCLUDE.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- Confusion Matrix Section -->
        <div class="card metric-card-group">
             <div class="card-header">
                 <h3><i class="fas fa-table mr-2"></i>3x3 Confusion Matrix (Human vs. AI)</h3>
             </div>
             <div class="card-body">
                <p class="explanation small mb-2" style="font-size: 0.75rem;">
                    <i class="fas fa-info-circle mr-1"></i>
                    Rows: Actual (Human) decisions, Columns: AI Prediction decisions.
                </p>
                <div class="table-responsive">
                    <table class="table matrix-table table-sm">
                        <thead class="thead-light">
                            <tr>
                                <th scope="col" class="actual-header">&nbsp;</th>
                                <th scope="col" colspan="{{ labels_order|length }}" class="pred-header text-center">AI Prediction</th>
                            </tr>
                            <tr>
                                <th scope="col" class="actual-header">Actual (Human)</th>
                                {% for label in labels_order %}<th scope="col" class="pred-header">{{ label }}</th>{% endfor %}
                            </tr>
                        </thead>
                        <tbody>
                            {% for i in range(labels_order|length) %}
                            <tr>
                                <th scope="row" class="actual-header">{{ labels_order[i] }}</th>
                                {% for j in range(labels_order|length) %}
                                <td class="{{ 'cm-correct' if i == j else 'cm-incorrect' }}">{{ matrix_3x3.matrix_data[i][j] }}</td>
                                {% endfor %}
                            </tr>
                            {% endfor %}
                        </tbody>
                    </table>
                </div>
            </div>
        </div>
        
        <!-- Per-Class Metrics Section -->
        <div class="card metric-card-group">
             <div class="card-header">
                 <h3><i class="fas fa-chart-bar mr-2"></i>Per-Class Metrics (for I, M, E)</h3>
             </div>
             <div class="card-body">
                 <div class="row">
                    {% for label, c_metrics in class_metrics.items() %}
                    <div class="col-md-4">
                        <div class="metric-value-card">
                             <h4 style="color: #6b46c1; margin-bottom: 0.75rem; font-size: 0.9rem;">Class: {{ label }}</h4>
                             <div style="text-align: left; font-size: 0.75rem;">
                                 <strong>Precision:</strong> {{ "%.2f"|format(c_metrics.precision) }} 
                                 <small class="explanation">Correctly AI-labeled '{{label}}' / Total AI-labeled '{{label}}'.</small>
                                 <hr class="my-1"> 
                                 <strong>Recall (Sensitivity):</strong> {{ "%.2f"|format(c_metrics.recall) }} 
                                 <small class="explanation">Correctly AI-labeled '{{label}}' / Total Human-labeled '{{label}}'.</small>
                                 <hr class="my-1"> 
                                 <strong>F1-Score:</strong> {{ "%.2f"|format(c_metrics.f1_score) }} 
                                 <small class="explanation">Balance of P & R for '{{label}}'.</small>
                                 <hr class="my-1"> 
                                 <strong>Specificity:</strong> {{ "%.2f"|format(c_metrics.specificity) }} 
                                 <small class="explanation">Correctly AI-labeled Not '{{label}}' / Total Human Not '{{label}}'.</small>
                             </div>
                         </div>
                    </div>
                    {% endfor %}
                </div>
            </div>
        </div>

        <!-- Binary Task Metrics Section -->
        <div class="card metric-card-group">
            <div class="card-header">
                <h3><i class="fas fa-bullseye mr-2"></i>Binary Task Metrics (Focus: Identifying "INCLUDE")</h3>
            </div>
            <div class="card-body">
                <p class="explanation small mb-2" style="font-size: 0.75rem;">
                    <i class="fas fa-info-circle mr-1"></i>
                    Evaluates AI for finding INCLUDEs (MAYBE/EXCLUDE are treated as "Not Include").
                </p>
                 <div class="row">
                    <div class="col-lg-3 col-md-6">
                         <div class="metric-value-card">
                            <strong>Sensitivity (Recall)</strong> 
                            <span class="metric-value">{{ "%.2f"|format(metrics.sensitivity_include * 100) }}%</span>
                            <p class="explanation">AI found Human 'INCLUDE' as 'INCLUDE'.</p>
                        </div>
                    </div>
                    <div class="col-lg-3 col-md-6">
                        <div class="metric-value-card">
                            <strong>Precision</strong> 
                            <span class="metric-value">{{ "%.2f"|format(metrics.precision_include * 100) }}%</span>
                            <p class="explanation">AI 'INCLUDE' was Human 'INCLUDE'.</p>
                        </div>
                    </div>
                    <div class="col-lg-3 col-md-6">
                         <div class="metric-value-card">
                            <strong>F1-Score</strong> 
                            <span class="metric-value">{{ "%.2f"|format(metrics.f1_include) }}</span>
                            <p class="explanation">Balance for INCLUDE task.</p>
                        </div>
                    </div>
                    <div class="col-lg-3 col-md-6">
                         <div class="metric-value-card">
                             <strong>Specificity</strong> 
                             <span class="metric-value">{{ "%.2f"|format(metrics.specificity_for_include_task * 100) }}%</span>
                             <p class="explanation">AI found Human 'Not INCLUDE' (M or E) as 'Not INCLUDE' (M or E).</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Workload & MAYBE Analysis Section -->
        <div class="card metric-card-group">
             <div class="card-header">
                 <h3><i class="fas fa-tasks mr-2"></i>Workload & "MAYBE" Analysis</h3>
             </div>
             <div class="card-body">
                  <div class="row">
                     <div class="col-md-4">
                          <div class="metric-value-card">
                             <strong>Workload Reduction</strong> 
                             <span class="metric-value">{{ "%.1f"|format(metrics.workload_reduction) }}%</span>
                             <p class="explanation">% of total items where both Human and AI agreed on EXCLUDE.</p>
                         </div>
                     </div>
                     <div class="col-md-4">
                          <div class="metric-value-card">
                             <strong>AI MAYBE Rate</strong> 
                             <span class="metric-value">{{ "%.1f"|format(metrics.ai_maybe_rate * 100) }}%</span>
                             <p class="explanation">% of items AI labeled 'MAYBE'.</p>
                         </div>
                     </div>
                     <div class="col-md-4">
                          <div class="metric-value-card">
                              <strong>Human MAYBE Rate</strong> 
                              <span class="metric-value">{{ "%.1f"|format(metrics.human_maybe_rate * 100) }}%</span>
                              <p class="explanation">% of items Human labeled 'MAYBE'.</p>
                         </div>
                     </div>
                 </div>
                 {% if maybe_resolution %}
                 <h4 class="mt-3 mb-2" style="color: #6b46c1; font-size: 0.9rem;">
                     <i class="fas fa-question-circle mr-2"></i>"MAYBE" Resolution Counts:
                 </h4>
                  <ul class="list-group maybe-list">
                     <li class="list-group-item">AI=MAYBE, Human=INCLUDE: <span class="badge badge-pill badge-info">{{ maybe_resolution.ai_maybe_to_human_include }}</span> (AI uncertain on relevant item)</li>
                     <li class="list-group-item">AI=MAYBE, Human=EXCLUDE: <span class="badge badge-pill badge-info">{{ maybe_resolution.ai_maybe_to_human_exclude }}</span> (AI uncertain on irrelevant item)</li>
                     <li class="list-group-item">AI=MAYBE, Human=MAYBE: <span class="badge badge-pill badge-success">{{ maybe_resolution.ai_maybe_to_human_maybe }}</span> (Both uncertain)</li>
                     <li class="list-group-item">Human=MAYBE, AI=INCLUDE: <span class="badge badge-pill badge-primary">{{ maybe_resolution.human_maybe_to_ai_include }}</span> (AI includes item Human was unsure of)</li>
                     <li class="list-group-item">Human=MAYBE, AI=EXCLUDE: <span class="badge badge-pill badge-primary">{{ maybe_resolution.human_maybe_to_ai_exclude }}</span> (AI excludes item Human was unsure of)</li>
                 </ul>
                 {% endif %}
            </div>
        </div>
        
    {% else %}
         <div class="alert alert-warning">
             <i class="fas fa-exclamation-triangle mr-2"></i>
             <strong>Metrics calculation requires valid decisions.</strong> Please ensure AI and Human decisions (INCLUDE, MAYBE, or EXCLUDE) were provided for all test items.
         </div>
    {% endif %}

    <!-- Comparison Table Section -->
    {% if comparison %}
        <div class="card metric-card-group">
             <div class="card-header">
                 <h3><i class="fas fa-list mr-2"></i>Individual Item Comparison</h3>
             </div>
             <div class="card-body">
                 <div class="table-responsive">
                     <table class="table comparison-table table-sm table-hover">
                         <thead>
                             <tr>
                                 <th>#</th>
                                 <th>Title</th>
                                 <th>AI Decision</th>
                                 <th>Your Decision</th>
                                 <th>Match?</th>
                             </tr>
                         </thead>
                         <tbody>
                             {% for item in comparison %}
                             <tr>
                                 <td>{{ loop.index }}</td>
                                 <td>{{ item.title|truncate(50) if item.title else 'N/A' }}</td>
                                 <td>
                                     {% if item.ai_decision=='INCLUDE' %}
                                         <span class="badge badge-include">I</span>
                                     {% elif item.ai_decision=='EXCLUDE' %}
                                         <span class="badge badge-exclude">E</span>
                                     {% elif item.ai_decision=='MAYBE' %}
                                         <span class="badge badge-maybe">M</span>
                                     {% else %}
                                         <span class="badge badge-secondary">{{item.ai_decision}}</span>
                                     {% endif %}
                                 </td>
                                 <td>
                                     {% if item.human_decision=='INCLUDE' %}
                                         <span class="badge badge-include">I</span>
                                     {% elif item.human_decision=='EXCLUDE' %}
                                         <span class="badge badge-exclude">E</span>
                                     {% elif item.human_decision=='MAYBE' %}
                                         <span class="badge badge-maybe">M</span>
                                     {% else %}
                                         <span class="badge badge-secondary">{{item.human_decision}}</span>
                                     {% endif %}
                                 </td>
                                 <td class="{{'match-true' if item.match else 'match-false'}}">
                                     <strong>{{'Yes' if item.match else 'No'}}</strong>
                                 </td>
                             </tr>
                             {% endfor %}
                         </tbody>
                     </table>
                 </div>
             </div>
        </div>
    {% else %}
        <p class="mt-3 text-muted" style="font-size: 0.8rem;">
            <i class="fas fa-info-circle mr-1"></i>
            No comparison data available (likely because no human decisions were submitted for the test sample).
        </p>
    {% endif %}
    
    <!-- Definitions Section (Collapsible) -->
    <div class="card metric-card-group definitions-card">
        <div class="card-header" id="definitionsHeader">
            <h3 class="mb-0">
                 <button class="btn btn-link btn-block text-left collapsed" type="button" data-toggle="collapse" data-target="#definitionsCollapse" aria-expanded="false" aria-controls="definitionsCollapse">
                     <i class="fas fa-book mr-2"></i>Metric Definitions Guide 
                     <small class="ml-2">(Click to expand/collapse)</small>
                 </button>
             </h3>
         </div>
        <div id="definitionsCollapse" class="collapse" aria-labelledby="definitionsHeader">
            <div class="card-body">
                 <dl class="row small">
                     <dt class="col-sm-3">Overall Accuracy</dt><dd class="col-sm-9">Proportion of AI decisions (I/M/E) matching Human.</dd>
                     <dt class="col-sm-3">Cohen's Kappa</dt><dd class="col-sm-9">AI-Human agreement (chance-corrected). -1 (disagree) to 1 (perfect); >0.8 Exc, 0.6-0.8 Good.</dd>
                     <dt class="col-sm-3">Discrepancy Rate</dt><dd class="col-sm-9">100% - Overall Accuracy %.</dd>
                     <dt class="col-sm-3">3x3 Confusion Matrix</dt><dd class="col-sm-9">Breakdown of Human vs AI labels (I/M/E). Diagonal = agreement. Colors: Green=Correct, Red=Incorrect.</dd>
                     <dt class="col-sm-3">Per-Class Precision</dt><dd class="col-sm-9">For a class (e.g. INCLUDE): True Positives / (True Positives + False Positives). Of those AI called Class X, how many actually were Class X?</dd>
                     <dt class="col-sm-3">Per-Class Recall</dt><dd class="col-sm-9">For a class: True Positives / (True Positives + False Negatives). Of all actual Class X, how many did AI find?</dd>
                     <dt class="col-sm-3">Per-Class F1</dt><dd class="col-sm-9">Harmonic mean of Precision & Recall for a class. Good balance measure.</dd>
                     <dt class="col-sm-3">Per-Class Specificity</dt><dd class="col-sm-9">For a class: True Negatives / (True Negatives + False Positives). Of all actual Not Class X, how many did AI correctly label as Not Class X?</dd>
                     <dt class="col-sm-3">Binary Sensitivity (INCLUDE)</dt><dd class="col-sm-9">Recall for the INCLUDE class when M/E are grouped as 'Not Include'.</dd>
                     <dt class="col-sm-3">Binary Specificity (INCLUDE task)</dt><dd class="col-sm-9">Of studies Human labeled Maybe/Exclude, % AI also labeled Maybe/Exclude.</dd>
                     <dt class="col-sm-3">Workload Reduction</dt><dd class="col-sm-9">% of total studies where both Human and AI agreed on EXCLUDE.</dd>
                     <dt class="col-sm-3">AI/Human MAYBE Rate</dt><dd class="col-sm-9">% of studies labeled 'MAYBE' by AI/Human. High AI MAYBE may mean conservative AI/unclear criteria.</dd>
                     <dt class="col-sm-3">MAYBE Resolution</dt><dd class="col-sm-9">How 'MAYBE' by one party was classified by the other; shows nature of uncertainty.</dd>
                     <dt class="col-sm-3">Critical Error Rate (I→E)</dt><dd class="col-sm-9">% of total studies where Human=INCLUDE but AI=EXCLUDE. High value indicates potentially missed relevant studies.</dd>
                 </dl>
             </div>
        </div>
    </div>
{% endblock %}